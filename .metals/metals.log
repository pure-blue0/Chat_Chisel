2024.02.01 11:35:01 INFO  Started: Metals version 1.2.0 in folders '/home/ysyx/Project/chisel_gen' for client Visual Studio Code 1.81.1.
2024.02.01 11:35:02 WARN  Build server is not auto-connectable.
2024.02.01 11:35:02 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/btb.scala
2024.02.01 11:35:12 INFO  no build target found for /home/ysyx/Project/chisel_gen/src/main/scala/btb.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.02.01 11:35:14 INFO  time: code lens generation in 11s
Feb 01, 2024 11:35:30 AM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2024.02.01 15:57:09 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/datacache.scala
Feb 01, 2024 3:57:11 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16
2024.02.01 21:24:33 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/control.scala
2024.02.01 23:00:52 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/control.scala
scala.meta.tokenizers.TokenizeException: <input>:113: error: illegal character '\uff0c'
    "b0010111".U -> 1.Uï¼Œ
                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.01 23:01:45 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/control.scala
2024.02.01 23:06:05 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/regfile.scala
2024.02.01 23:06:07 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/regfile.scala
2024.02.01 23:06:22 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/immgen.scala
2024.02.02 00:04:55 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 00:04:55 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 00:04:56 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 00:06:04 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 00:11:06 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.02 01:10:00 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
Feb 02, 2024 1:10:00 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1509
2024.02.02 01:10:00 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 01:11:12 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 01:11:29 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 01:14:17 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 01:14:17 WARN  Using indexes to guess the definition of id_ex_isbranch_reg
2024.02.02 01:14:17 WARN  Using indexes to guess the definition of id_ex_immsrc_reg
2024.02.02 01:14:54 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 01:15:06 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.02 01:15:08 INFO  Shutting down server
2024.02.02 01:15:08 INFO  shutting down Metals
2024.02.02 01:15:08 ERROR Unexpected error initializing server: 
org.eclipse.lsp4j.jsonrpc.ResponseErrorException: Request window/showMessageRequest failed with message: Canceled
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleResponse(RemoteEndpoint.java:209)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:193)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 01:15:08 INFO  Exiting server
2024.02.02 10:15:11 INFO  Started: Metals version 1.2.0 in folders '/home/ysyx/Project/chisel_gen' for client Visual Studio Code 1.81.1.
2024.02.02 10:15:12 WARN  Build server is not auto-connectable.
2024.02.02 10:15:12 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.02 10:15:12 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 10:15:20 INFO  no build target found for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.02.02 10:15:24 INFO  time: code lens generation in 10s
2024.02.02 10:20:09 INFO  Started: Metals version 1.2.0 in folders '/home/ysyx/Project/chisel_gen' for client Visual Studio Code 1.81.1.
2024.02.02 10:20:13 WARN  Build server is not auto-connectable.
2024.02.02 10:20:13 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 10:20:25 INFO  no build target found for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.02.02 10:20:38 INFO  time: code lens generation in 15s
2024.02.02 10:20:38 INFO  time: code lens generation in 5.01s
2024.02.02 10:41:43 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:166: error: unclosed string literal
  val csrInst = io.inst(6, 0).asUInt === "b1110011
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:41:50 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.02 10:48:25 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 0011000 | 00010 |  00000 | 000 | 00000 | 1110011Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:28 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 001100000010 |  00000 | 000 | 00000 | 1110011Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:32 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 00110000001000000 | 000 | 00000 | 1110011Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:36 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 00110000001000000000 | 00000 | 1110011Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:37 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 00110000001000000000 00000 | 1110011Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:38 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 0011000000100000000000000 | 1110011Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:41 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 00110000001000000000000001110011Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:45 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 00110000001000000000000001110011//Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:46 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 00110000001000000000000001110011 //Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:48:49 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:115: error: Non-zero integral values may not have a leading zero.
  val mert_out = io.inst === 00110000001000000000000001110011" //Control.MERT_INSTRUCTION
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:49:24 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:116: error: Non-zero integral values may not have a leading zero.
  val wfi_out = io.inst === 0011000 | 00010 |  00000 | 000 | 00000 | 1110011 //Control.WFI_INSTRUCTION
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:49:28 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:116: error: Non-zero integral values may not have a leading zero.
  val wfi_out = io.inst === 001100000010 |  00000 | 000 | 00000 | 1110011 //Control.WFI_INSTRUCTION
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:49:29 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:116: error: Non-zero integral values may not have a leading zero.
  val wfi_out = io.inst === 00110000001000000 | 000 | 00000 | 1110011 //Control.WFI_INSTRUCTION
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:49:31 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:116: error: Non-zero integral values may not have a leading zero.
  val wfi_out = io.inst === 00110000001000000000 | 00000 | 1110011 //Control.WFI_INSTRUCTION
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:49:33 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:116: error: Non-zero integral values may not have a leading zero.
  val wfi_out = io.inst === 0011000000100000000000000 | 1110011 //Control.WFI_INSTRUCTION
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:49:35 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:116: error: Non-zero integral values may not have a leading zero.
  val wfi_out = io.inst === 00110000001000000000000001110011 //Control.WFI_INSTRUCTION
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:49:39 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:116: error: unclosed string literal
  val wfi_out = io.inst === "b00110000001000000000000001110011 //Control.WFI_INSTRUCTION
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:13 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000 | 00101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:16 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000 00101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:17 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000                00101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:17 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000                      00101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:18 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000                     00101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:19 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000      00101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:19 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000  00101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:20 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               000100000101 |  00000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:22 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               00010000010100000 | 000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:23 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               00010000010100000000 | 00000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:25 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000001010000000000000 | 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:27 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               0001000001010000000000000 1110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.02 10:50:27 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
scala.meta.tokenizers.TokenizeException: <input>:117: error: Non-zero integral values may not have a leading zero.
                               00010000010100000000000001110011
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Feb 02, 2024 10:50:34 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 905
Feb 02, 2024 10:57:47 AM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2024.02.02 10:58:16 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 11:53:50 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
Feb 02, 2024 12:06:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1220
2024.02.02 12:29:09 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.02 12:29:09 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.02 12:29:27 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.02 12:36:18 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
Feb 02, 2024 12:54:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1646
2024.02.02 12:55:38 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.02 12:57:35 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.02 13:05:22 WARN  Using indexes to guess the definition of io
2024.02.02 13:05:47 WARN  Using indexes to guess the definition of io
2024.02.02 13:05:47 WARN  Using indexes to guess the definition of io
2024.02.02 13:06:44 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.02 13:07:29 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.02 13:07:34 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.02 13:11:00 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.02 13:21:47 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 13:24:30 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.02 13:24:31 WARN  Using indexes to guess the definition of io
Feb 02, 2024 1:39:44 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Feb 02, 2024 2:20:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2472
Feb 02, 2024 2:20:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2473
Feb 02, 2024 2:20:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2475
2024.02.02 14:22:18 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/branch.scala
Feb 02, 2024 2:22:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2494
2024.02.02 14:22:30 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/immgen.scala
Feb 02, 2024 2:22:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2512
2024.02.02 14:51:27 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 14:58:55 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 14:58:57 INFO  time: code lens generation in 16s
2024.02.02 14:59:03 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 15:14:41 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/aluselect.scala
2024.02.02 15:23:11 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/alu.scala
2024.02.02 15:23:26 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/alu.scala
Feb 02, 2024 3:23:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2808
2024.02.02 15:23:54 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/targetgen.scala
2024.02.02 15:23:57 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/targetgen.scala
2024.02.02 16:14:17 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/targetgen.scala
2024.02.02 16:56:07 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.02 16:56:07 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.02 16:56:07 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.02 17:04:48 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.02 17:10:13 WARN  Using indexes to guess the definition of Execute
2024.02.02 17:10:13 WARN  Using indexes to guess the definition of Execute
2024.02.02 17:10:33 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.02 17:10:35 WARN  Using indexes to guess the definition of csr_write_enable_out_reg
2024.02.02 17:10:36 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.02 17:11:04 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.02 17:19:21 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.02 17:51:17 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/datacache.scala
2024.02.02 18:19:36 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/writeback.scala
2024.02.02 21:16:02 INFO  time: code lens generation in 5.26s
Exception in thread "pool-3-thread-1" Feb 02, 2024 9:16:03 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3665
java.lang.Error: java.lang.InterruptedException
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	... 2 more
Feb 02, 2024 9:16:03 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3662
2024.02.02 21:16:05 WARN  Using indexes to guess the definition of reg_pc_reg
2024.02.02 21:16:06 WARN  Using indexes to guess the definition of csr_read_data_out_reg
2024.02.02 21:16:14 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
Feb 02, 2024 10:38:02 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3725
2024.02.03 00:29:24 INFO  Shutting down server
2024.02.03 00:29:27 INFO  shutting down Metals
2024.02.03 00:29:40 ERROR Unexpected error initializing server: 
org.eclipse.lsp4j.jsonrpc.ResponseErrorException: Request window/showMessageRequest failed with message: Canceled
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleResponse(RemoteEndpoint.java:209)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:193)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.03 10:30:15 INFO  Started: Metals version 1.2.0 in folders '/home/ysyx/Project/chisel_gen' for client Visual Studio Code 1.81.1.
2024.02.03 10:30:15 WARN  Build server is not auto-connectable.
2024.02.03 11:14:18 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 11:14:21 INFO  no build target found for /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.02.03 11:14:22 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 11:14:22 INFO  time: code lens generation in 3.31s
2024.02.03 11:14:22 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 11:15:06 ERROR Failed to tokenize input for semantic tokens for /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
scala.meta.tokenizers.TokenizeException: <input>:99: error: empty quoted identifier
```scala
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getBackquotedIdent(LegacyScanner.scala:485)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:337)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2024.02.03 11:32:14 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 11:54:33 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 11:57:32 WARN  Using indexes to guess the definition of retired
2024.02.03 12:01:02 WARN  Using indexes to guess the definition of dataCache
2024.02.03 12:01:09 WARN  Using indexes to guess the definition of dataCache
2024.02.03 12:14:18 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 12:14:18 WARN  Using indexes to guess the definition of pcsrc_reg
2024.02.03 12:14:25 WARN  Using indexes to guess the definition of branch
2024.02.03 12:28:07 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 12:28:07 WARN  Using indexes to guess the definition of csr_write_address_out_reg
2024.02.03 12:31:16 WARN  Using indexes to guess the definition of wb_rd_reg
2024.02.03 12:31:16 WARN  Using indexes to guess the definition of pcsrc_reg
2024.02.03 12:31:18 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.03 12:53:12 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/writeback.scala
2024.02.03 12:53:23 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/writeback.scala
2024.02.03 12:53:25 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/targetgen.scala
2024.02.03 13:08:04 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/writeback.scala
2024.02.03 13:08:13 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/control.scala
2024.02.03 13:09:53 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
Feb 03, 2024 3:04:46 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Feb 03, 2024 3:29:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1190
Feb 03, 2024 4:08:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1225
Exception in thread "pool-3-thread-1" java.lang.Error: java.lang.InterruptedException
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	... 2 more
2024.02.03 16:31:55 WARN  Using indexes to guess the definition of trapped
2024.02.03 16:31:55 WARN  Using indexes to guess the definition of trapped
2024.02.03 16:31:58 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.03 17:00:11 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.03 18:16:56 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/btb.scala
Feb 03, 2024 6:16:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1581
2024.02.03 22:20:52 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
Feb 03, 2024 10:53:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1651
2024.02.03 23:13:15 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.04 00:11:02 INFO  Shutting down server
2024.02.04 00:11:02 INFO  shutting down Metals
2024.02.04 00:11:02 INFO  Exiting server
2024.02.04 10:32:41 INFO  Started: Metals version 1.2.0 in folders '/home/ysyx/Project/chisel_gen' for client Visual Studio Code 1.81.1.
2024.02.04 10:32:43 WARN  Build server is not auto-connectable.
2024.02.04 10:32:43 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala
2024.02.04 10:32:50 INFO  no build target found for /home/ysyx/Project/chisel_gen/src/main/scala/fetch.scala. Using presentation compiler with project's scala-library version: 3.3.1
Feb 04, 2024 10:32:51 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
Feb 04, 2024 10:32:51 AM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Feb 04, 2024 10:32:51 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8
2024.02.04 10:32:55 INFO  time: code lens generation in 4.48s
2024.02.04 10:42:35 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/decode.scala
2024.02.04 10:48:36 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.04 10:48:56 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/execute.scala
2024.02.04 10:55:53 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/datacache.scala
2024.02.04 10:55:55 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/memory.scala
2024.02.04 10:58:38 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/writeback.scala
2024.02.04 11:13:02 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
2024.02.04 11:13:02 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
2024.02.04 11:13:02 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
2024.02.04 11:13:38 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/aluselect.scala
2024.02.04 11:16:38 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
2024.02.04 11:17:11 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.04 11:34:20 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
Feb 04, 2024 11:53:30 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1295
2024.02.04 11:54:11 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.04 12:00:34 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:00:34 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:00:34 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:00:37 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:01:58 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:01:58 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:02:08 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/bht.scala
2024.02.04 12:02:11 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:02:14 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:15:20 WARN  Using indexes to guess the definition of execute
2024.02.04 12:19:50 WARN  Using indexes to guess the definition of writeback
Feb 04, 2024 12:20:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1803
2024.02.04 12:22:49 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:25:51 WARN  Using indexes to guess the definition of writeback
2024.02.04 12:28:39 WARN  Using indexes to guess the definition of memory
2024.02.04 12:29:17 WARN  Using indexes to guess the definition of execute
2024.02.04 12:29:26 WARN  Using indexes to guess the definition of memory
2024.02.04 12:40:03 WARN  Using indexes to guess the definition of execute
2024.02.04 12:40:13 WARN  Using indexes to guess the definition of memory
2024.02.04 12:40:19 WARN  Using indexes to guess the definition of memory
2024.02.04 12:40:31 WARN  Using indexes to guess the definition of io
2024.02.04 12:40:31 WARN  Using indexes to guess the definition of forward2
2024.02.04 12:40:31 WARN  Using indexes to guess the definition of io
2024.02.04 12:40:31 WARN  Using indexes to guess the definition of execute
2024.02.04 12:43:20 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 12:46:23 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
2024.02.04 12:48:32 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
2024.02.04 12:48:33 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
2024.02.04 12:51:14 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/hazard.scala
2024.02.04 13:28:52 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/csr.scala
Feb 04, 2024 2:08:40 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2024.02.04 14:08:48 WARN  no build target for: /home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:08:48 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:08:48 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:10:17 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/excute.scala
2024.02.04 14:11:03 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 14:12:02 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 14:13:56 WARN  no build target for: /home/ysyx/Project/chisel_gen/src/main/scala/core.scala
2024.02.04 14:14:20 WARN  no build target for: /home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:14:20 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:14:21 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:15:10 WARN  no build target for: /home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:15:10 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:15:10 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:15:20 INFO  running '/opt/jdk/jdk1.8.0_181/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -Dsbt.version=1.9.7 -jar /tmp/metals7765489871224848552/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.02.04 14:15:21 ERROR [info] [launcher] getting org.scala-sbt sbt 1.9.7  (this may take some time)...
2024.02.04 14:15:30 INFO  [info] Updated file /home/ysyx/Project/chisel_gen/project/build.properties: set sbt.version to 1.9.7
2024.02.04 14:15:30 INFO  [info] welcome to sbt 1.9.7 (Oracle Corporation Java 1.8.0_181)
2024.02.04 14:15:30 WARN  Could not find semantic tokens for: file:///home/ysyx/Project/chisel_gen/build.sbt
2024.02.04 14:15:31 INFO  [info] loading settings for project chisel_gen-build-build from metals.sbt ...
2024.02.04 14:15:31 INFO  [info] loading project definition from /home/ysyx/Project/chisel_gen/project/project
2024.02.04 14:15:33 INFO  [info] loading settings for project chisel_gen-build from metals.sbt ...
2024.02.04 14:15:33 INFO  [info] loading project definition from /home/ysyx/Project/chisel_gen/project
2024.02.04 14:17:37 INFO  [success] Generated .bloop/chisel_gen-build.json
2024.02.04 14:17:37 INFO  [success] Total time: 124 s (02:04), completed Feb 4, 2024 2:17:37 PM
2024.02.04 14:17:40 ERROR /home/ysyx/Project/chisel_gen/build.sbt:9: warning: method sonatypeRepo in class ResolverFunctions is deprecated (since 1.7.0): Use sonatypeOssRepos instead e.g. `resolvers ++= Resolver.sonatypeOssRepos("snapshots")`
2024.02.04 14:17:40 ERROR   Resolver.sonatypeRepo("releases")
2024.02.04 14:17:40 ERROR            ^
2024.02.04 14:17:40 INFO  [info] loading settings for project chisel_gen from build.sbt ...
2024.02.04 14:17:40 INFO  [info] set current project to chisel_gen (in build file:/home/ysyx/Project/chisel_gen/)
2024.02.04 14:17:43 INFO  [success] Generated .bloop/chisel_gen.json
2024.02.04 14:17:43 INFO  [success] Generated .bloop/chisel_gen-test.json
2024.02.04 14:17:43 INFO  [success] Total time: 2 s, completed Feb 4, 2024 2:17:44 PM
2024.02.04 14:17:44 INFO  time: ran 'sbt bloopInstall' in 2m23s
2024.02.04 14:17:44 INFO  Attempting to connect to the build server...
2024.02.04 14:17:44 INFO  Bloop uses /opt/jdk/jdk1.8.0_181 defined at /home/ysyx/.bloop/bloop.json
2024.02.04 14:17:48 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/ysyx/Project/chisel_gen/.metals/bsp.trace.json or /home/ysyx/.cache/metals/bsp.trace.json
2024.02.04 14:18:04 WARN  Stopped configuration of Scala SemanticDB in 2.12.13 projects: Error downloading org.scalameta:semanticdb-scalac_2.12.13:4.8.14
  not found: /home/ysyx/.ivy2/local/org.scalameta/semanticdb-scalac_2.12.13/4.8.14/ivys/ivy.xml
  not found: https://repo1.maven.org/maven2/org/scalameta/semanticdb-scalac_2.12.13/4.8.14/semanticdb-scalac_2.12.13-4.8.14.pom
After retry no existing semanticdb version found for scala version 2.12.13
2024.02.04 14:18:04 INFO  Attempting to connect to the build server...
2024.02.04 14:18:04 INFO  Bloop uses /opt/jdk/jdk1.8.0_181 defined at /home/ysyx/.bloop/bloop.json
2024.02.04 14:18:04 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/ysyx/Project/chisel_gen/project/.metals/bsp.trace.json or /home/ysyx/.cache/metals/bsp.trace.json
2024.02.04 14:18:04 INFO  time: Connected to build server in 19s
2024.02.04 14:18:04 INFO  Connected to Build server: Bloop v1.5.13
2024.02.04 14:18:04 INFO  time: Imported build in 0.17s
2024.02.04 14:18:10 INFO  time: indexed workspace in 5.53s
2024.02.04 14:18:10 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.04 14:18:10 INFO  compiling chisel_gen (20 scala sources)
2024.02.04 14:18:12 INFO  time: compiled chisel_gen in 1.47s
Feb 04, 2024 2:18:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3251
2024.02.04 14:18:25 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.04 14:18:25 INFO  compiling chisel_gen (20 scala sources)
Feb 04, 2024 2:18:25 PM scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
2024.02.04 14:18:25 INFO  time: compiled chisel_gen in 0.2s
2024.02.04 14:18:49 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.04 14:18:49 INFO  compiling chisel_gen (19 scala sources)
2024.02.04 14:18:52 INFO  time: compiled chisel_gen in 2.74s
2024.02.04 14:18:52 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.04 14:18:52 INFO  compiling chisel_gen (19 scala sources)
2024.02.04 14:18:53 INFO  time: compiled chisel_gen in 1.15s
Exception in thread "pool-6-thread-1" java.lang.Error: java.lang.InterruptedException
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	... 2 more
2024.02.04 14:20:36 WARN  Using indexes to guess the definition of Bool
2024.02.04 14:20:37 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.04 14:20:37 INFO  compiling chisel_gen (19 scala sources)
2024.02.04 14:20:42 INFO  time: compiled chisel_gen in 4.91s
2024.02.04 14:23:55 INFO  skipping build import with status 'Installed'
2024.02.04 19:10:45 INFO  Shutting down server
2024.02.04 19:10:45 INFO  shutting down Metals
2024.02.04 19:10:49 INFO  Shut down connection with build server.
2024.02.04 19:10:50 INFO  Shut down connection with build server.
2024.02.05 18:10:56 INFO  Started: Metals version 1.2.0 in folders '/home/ysyx/Project/chisel_gen' for client Visual Studio Code 1.81.1.
Feb 05, 2024 6:10:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
2024.02.05 18:10:59 INFO  Attempting to connect to the build server...
2024.02.05 18:11:00 INFO  skipping build import with status 'Installed'
2024.02.05 18:10:59 INFO  Bloop uses /opt/jdk/jdk1.8.0_181 defined at /home/ysyx/.bloop/bloop.json
2024.02.05 18:11:08 INFO  no build target found for /home/ysyx/Project/chisel_gen/src/main/scala/core.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.02.05 18:11:23 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/ysyx/Project/chisel_gen/.metals/bsp.trace.json or /home/ysyx/.cache/metals/bsp.trace.json
2024.02.05 18:11:27 INFO  Attempting to connect to the build server...
2024.02.05 18:11:27 INFO  Bloop uses /opt/jdk/jdk1.8.0_181 defined at /home/ysyx/.bloop/bloop.json
2024.02.05 18:11:27 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/ysyx/Project/chisel_gen/project/.metals/bsp.trace.json or /home/ysyx/.cache/metals/bsp.trace.json
2024.02.05 18:11:27 INFO  time: Connected to build server in 28s
2024.02.05 18:11:27 INFO  Connected to Build server: Bloop v1.5.13
2024.02.05 18:11:28 INFO  time: Imported build in 0.41s
2024.02.05 18:11:33 INFO  time: indexed workspace in 5.16s
2024.02.05 18:11:35 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 18:11:35 INFO  compiling chisel_gen (19 scala sources)
2024.02.05 18:11:59 INFO  time: compiled chisel_gen in 23s
2024.02.05 18:11:59 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 18:19:08 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 20:41:20 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 20:41:50 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 20:41:50 INFO  compiling chisel_gen (1 scala source)
2024.02.05 20:41:54 INFO  time: compiled chisel_gen in 3.18s
2024.02.05 20:51:50 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 20:56:05 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
Exception in thread "pool-5-thread-1" java.lang.Error: java.lang.InterruptedException
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.$anonfun$onCompilerJobQueue$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	... 2 more
2024.02.05 21:34:31 WARN  Using indexes to guess the definition of funct3
2024.02.05 21:35:44 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 21:35:44 INFO  compiling chisel_gen (1 scala source)
2024.02.05 21:35:52 INFO  time: compiled chisel_gen in 8.34s
2024.02.05 21:35:52 INFO  compiling chisel_gen (1 scala source)
2024.02.05 21:36:02 INFO  time: compiled chisel_gen in 9.03s
2024.02.05 21:36:24 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 21:36:24 INFO  compiling chisel_gen (1 scala source)
2024.02.05 21:36:27 INFO  time: compiled chisel_gen in 3.17s
2024.02.05 21:36:27 INFO  compiling chisel_gen (1 scala source)
2024.02.05 21:36:35 INFO  time: compiled chisel_gen in 7.94s
2024.02.05 21:36:51 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
2024.02.05 21:37:31 WARN  Bloop is runing with 1.8.0_181 but your code requires 1.8.0_181 to compile, this might cause some compilation issues when using JDK API unsupported by the Bloop's current JVM version
Feb 05, 2024 9:37:41 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Feb 05, 2024 9:38:00 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 667
Feb 05, 2024 9:38:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 676
